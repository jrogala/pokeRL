{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Using SDL2 binaries from pysdl2-dll 2.30.2\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.wrappers import GrayScaleObservation, ResizeObservation, TimeLimit\n",
    "\n",
    "from pokerl.env.pokemonblue import  PokemonBlueEnv\n",
    "from pokerl.env.wrappers import (\n",
    "    ObservationAddPokemonLevel,\n",
    "    ObservationAddPosition,\n",
    "    ObservationDict,\n",
    "    RewardDecreasingNoChange,\n",
    "    RewardDecreasingSteps,\n",
    "    RewardHistoryToInfo,\n",
    "    RewardIncreasingBadges,\n",
    "    RewardIncreasingCapturePokemon,\n",
    "    RewardIncreasingPokemonLevel,\n",
    "    RewardIncreasingPositionExploration,\n",
    "    RemoveSelectStartAction,\n",
    "    ppFlattenInfo,\n",
    ")\n",
    "\n",
    "from pokerl.env.wrappers.rewards import RewardIncreasingLandedAttack,RewardDecreasingLostBattle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(interactive=False) -> Env:\n",
    "    env = PokemonBlueEnv(interactive=interactive)\n",
    "    # Setting observation\n",
    "    env = ResizeObservation(env, 64)\n",
    "    env = GrayScaleObservation(env)\n",
    "    env = ObservationDict(env)\n",
    "    env = ObservationAddPosition(env)\n",
    "    env = ObservationAddPokemonLevel(env)\n",
    "    env = RemoveSelectStartAction(env)\n",
    "    # Setting reward\n",
    "    env = RewardDecreasingNoChange(env, 0.01)\n",
    "    env = RewardDecreasingSteps(env, .01)\n",
    "    env = RewardIncreasingBadges(env, 100)\n",
    "    env = RewardIncreasingCapturePokemon(env, 10)\n",
    "    env = RewardIncreasingPokemonLevel(env, 10)\n",
    "    env = RewardIncreasingLandedAttack(env, 0.05)\n",
    "    env = RewardDecreasingLostBattle(env, 0.1)\n",
    "    # env = RewardIncreasingPositionExploration(env, 1)\n",
    "    env = RewardHistoryToInfo(env)\n",
    "    # Post processing\n",
    "    # env = TimeLimit(env, 300)\n",
    "    # env = ppFlattenInfo(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import ppo\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "from pokerl.agent.tools import get_device\n",
    "\n",
    "# env = make_vec_env(create_env, n_envs=8)\n",
    "\n",
    "# model = ppo.PPO(\n",
    "#     \"MultiInputPolicy\",\n",
    "#     env,\n",
    "#     device=get_device(),\n",
    "#     verbose=1\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49cfe9f88f640939ba9445ea7119941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1941   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 131    |\n",
      "|    total_timesteps | 256000 |\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2944f3190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "def make_env(rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the initial seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = create_env()\n",
    "        env.reset(seed=(seed + rank))\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# config = {\n",
    "#     \"policy_type\": \"MultiInputPolicy\",\n",
    "#     \"total_timesteps\": 5000,\n",
    "#     \"env_name\": \"PokemonBlueEnv-v1\",\n",
    "# }\n",
    "\n",
    "# run = wandb.init(\n",
    "#     project=\"sb3\",\n",
    "#     config=config,\n",
    "#     sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "#     monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "#     save_code=True,  # optional\n",
    "# )\n",
    "\n",
    "nb_cpus = 16\n",
    "ep_length = 1e3\n",
    "subproc = SubprocVecEnv([make_env(i) for i in range(nb_cpus)])\n",
    "\n",
    "model = ppo.PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    subproc,\n",
    "    learning_rate=0.001,\n",
    "    n_steps=int(ep_length*nb_cpus),\n",
    "    batch_size=512,\n",
    "    n_epochs=10,\n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    verbose=2,\n",
    "    # callback=WandbCallback(),\n",
    ")\n",
    "model.learn(total_timesteps=ep_length*nb_cpus*nb_cpus, progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subproc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'screen': array([[100, 100,  91, ...,   0,   0,   0],\n",
       "         [163, 163,  79, ...,   0,   0,   0],\n",
       "         [ 43,  63,  50, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [ 97,  97,  97, ...,   0,   0,   0],\n",
       "         [ 97,  97,  97, ...,   0,   0,   0],\n",
       "         [ 86,  86,  86, ...,   0,   0,   0]], dtype=uint8),\n",
       "  'position': array([0., 0.], dtype=float16),\n",
       "  'pokemon_level': array([0, 0, 0, 0, 0, 0], dtype=uint8)},\n",
       " {'tick': 0,\n",
       "  'pokemon_level': array([5, 0, 0, 0, 0, 0]),\n",
       "  'badges': array(0),\n",
       "  'position': array([ 5,  5, 40]),\n",
       "  'absolute_position': array([26, -1]),\n",
       "  'owned_pokemon': array([8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'start_combat': False,\n",
       "  'rewardHistory': deque([], maxlen=10)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env = create_env(interactive=True)\n",
    "test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baptistepugnaire/Documents/Projects/GitHub/pokeRL/.venv/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "100%|██████████| 600/600 [00:01<00:00, 382.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_env = create_env(interactive=False)\n",
    "obs, _ = test_env.reset()\n",
    "\n",
    "dict_actions_counter = {} # Dictionary to store the number of times each action is taken\n",
    "model = ppo.PPO.load(\"../models/7cxs6l8i/model.zip\")\n",
    "\n",
    "for _ in tqdm(range(600)):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, _, _, _ = test_env.step(action)\n",
    "    if int(action) not in dict_actions_counter:\n",
    "        dict_actions_counter[int(action)] = 1\n",
    "    else:\n",
    "        dict_actions_counter[int(action)] += 1\n",
    "\n",
    "test_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 600}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dict_actions_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'screen': array([[142, 142, 130, ...,   0,   0,   0],\n",
       "         [232, 232, 112, ...,   0,   0,   0],\n",
       "         [ 62,  90,  71, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [138, 138, 138, ...,   0,   0,   0],\n",
       "         [138, 138, 138, ...,   0,   0,   0],\n",
       "         [123, 123, 123, ...,   0,   0,   0]], dtype=uint8),\n",
       "  'position': array([0., 0.], dtype=float16),\n",
       "  'pokemon_level': array([0, 0, 0, 0, 0, 0], dtype=uint8)},\n",
       " {'tick': 0,\n",
       "  'pokemon_level': array([5, 0, 0, 0, 0, 0]),\n",
       "  'badges': array(0),\n",
       "  'position': array([ 5,  5, 40]),\n",
       "  'absolute_position': array([26, -1]),\n",
       "  'owned_pokemon': array([8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'rewardHistory': deque([], maxlen=10000)})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = create_env(interactive=False)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baptistepugnaire/Documents/Projects/GitHub/pokeRL/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.helper to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.helper` for environment variables or `env.get_wrapper_attr('helper')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.helper.get_max_hp_pokemon(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:07<00:00, 278.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "env = create_env(interactive=False)\n",
    "env.reset()\n",
    "for _ in tqdm(range(2000)):\n",
    "    obs, reward, _, _, _ = env.step(2)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.356306172839506\n"
     ]
    }
   ],
   "source": [
    "NB_CPUS = 16\n",
    "EP_LENGTH = 2**14 # 16384\n",
    "NB_UPDATES = 2**8 # 256\n",
    "TOTAL_TIMESTEPS = EP_LENGTH*NB_CPUS*NB_UPDATES\n",
    "print(TOTAL_TIMESTEPS/(1800*3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13397967485796172"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.99**200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
