{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from gymnasium import Env, Wrapper, spaces\n",
    "\n",
    "\n",
    "class ObservationRemoveScreen(Wrapper):\n",
    "    \"\"\"Wrapper for reward based on pokemon level\"\"\"\n",
    "\n",
    "    def __init__(self, env: Env):\n",
    "        super().__init__(env)\n",
    "        if isinstance(env.observation_space, spaces.Dict):\n",
    "            # We add the position to the observation space dict\n",
    "            d_obs_space = env.observation_space.spaces\n",
    "            d_obs_space.pop(\"screen\")\n",
    "            self.observation_space = spaces.Dict(d_obs_space)\n",
    "        else:\n",
    "            raise Exception(\"You should wrap your env in ObservationDict before using ObservationAddPosition\")\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, truncated, terminated, info = self.env.step(action)\n",
    "        observation.pop(\"screen\")\n",
    "        return observation, reward, truncated, terminated, info\n",
    "\n",
    "    def reset(\n",
    "        self, *, seed: int | None = None, options: dict[str, Any] | None = None\n",
    "    ) -> tuple[dict[str, Any], dict[str, Any]]:\n",
    "        observation, info = self.env.reset(seed=seed, options=options)\n",
    "        observation.pop(\"screen\")\n",
    "        return observation, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import (\n",
    "    AutoResetWrapper,\n",
    "    FlattenObservation,\n",
    "    GrayScaleObservation,\n",
    "    NormalizeObservation,\n",
    "    RecordEpisodeStatistics,\n",
    "    ResizeObservation,\n",
    "    TimeLimit,\n",
    ")\n",
    "\n",
    "from pokerl.env.pokemonblue import PokemonBlueEnv\n",
    "from pokerl.env.wrappers import (\n",
    "    ObservationAddPokemonLevel,\n",
    "    ObservationAddPosition,\n",
    "    ObservationDict,\n",
    "    RemoveABAction,\n",
    "    RemoveSelectStartAction,\n",
    "    RewardCheckpoint,\n",
    "    RewardDecreasingNoChange,\n",
    "    RewardDecreasingSteps,\n",
    "    RewardHistoryToInfo,\n",
    "    RewardIncreasingBadges,\n",
    "    RewardIncreasingCapturePokemon,\n",
    "    RewardIncreasingPokemonLevel,\n",
    "    RewardIncreasingPositionExploration,\n",
    "    RewardStopCheckpoint,\n",
    "    StopAtPokemon,\n",
    "    ppFlattenInfo,\n",
    ")\n",
    "\n",
    "\n",
    "def create_env(interactive=False) -> gym.Env:\n",
    "    env = PokemonBlueEnv(\n",
    "        interactive=interactive,\n",
    "        save_state=\"game_start\"\n",
    "    )\n",
    "    # Setting observation\n",
    "    env = ResizeObservation(env, 128)\n",
    "    # env = GrayScaleObservation(env)\n",
    "    env = ObservationDict(env)\n",
    "    env = ObservationAddPosition(env)\n",
    "    env = ObservationRemoveScreen(env)\n",
    "    env = RemoveABAction(env)\n",
    "    env = RemoveSelectStartAction(env)\n",
    "    # env = ObservationAddPokemonLevel(env)\n",
    "    # Setting reward\n",
    "    # env = RewardDecreasingNoChange(env, .001)\n",
    "    env = RewardDecreasingSteps(env, 1)\n",
    "    # env = RewardIncreasingBadges(env, 100)\n",
    "    # env = RewardIncreasingCapturePokemon(env, 10)\n",
    "    # env = RewardIncreasingPokemonLevel(env, 10)\n",
    "    # env = RewardIncreasingPositionExploration(env, 1)\n",
    "    # env = RewardHistoryToInfo(env)\n",
    "    # Post processing\n",
    "    env = RewardStopCheckpoint(env)\n",
    "    env = TimeLimit(env, STEP_LIMIT)\n",
    "    # env = AutoResetWrapper(env)\n",
    "    env = FlattenObservation(env)\n",
    "    # env = NormalizeObservation(env)\n",
    "\n",
    "    # env = ppFlattenInfo(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import a2c, dqn, ppo, td3\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from pokerl.agent.tools import get_device\n",
    "\n",
    "env = create_env()\n",
    "\n",
    "ppo = ppo.PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    device=\"cpu\",\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce4d5f704ef42e0a46fc999d2830e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -50      |\n",
      "| time/              |          |\n",
      "|    fps             | 67       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011681395 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | -0.000418    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.24         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000945    |\n",
      "|    value_loss           | 88.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008303616 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00854     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001157996 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.00258      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -6.65e-05    |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 50            |\n",
      "|    ep_rew_mean          | -50           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 66            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020708132 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.59         |\n",
      "|    explained_variance   | -0.000439     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.56          |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000287     |\n",
      "|    value_loss           | 34.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003057632 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -0.00026     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.66         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000382    |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.9        |\n",
      "|    ep_rew_mean          | -49.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001553888 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.000735    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000534   |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.9        |\n",
      "|    ep_rew_mean          | -49.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006215332 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00104     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.8        |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007993879 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.000982    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 49.9       |\n",
      "|    ep_rew_mean          | -49.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00189585 |\n",
      "|    clip_fraction        | 0.00298    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.56      |\n",
      "|    explained_variance   | 0.000865   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.09       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.000228  |\n",
      "|    value_loss           | 8.19       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111182965 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.000572     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 5.96         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017756991 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.000973    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.939       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 4.32        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048158 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.000538    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.598       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    value_loss           | 3.14        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180566 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.000868    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 2.28        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009146142 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.00065     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.6         |\n",
      "|    ep_rew_mean          | -49.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 493          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033254651 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.00108      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.334        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00058     |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.6        |\n",
      "|    ep_rew_mean          | -49.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013477413 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.00125     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    value_loss           | 0.885       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.8        |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013034158 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.000739    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    value_loss           | 0.66        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008742074 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.00104     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 0.474       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014233801 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.000974    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    value_loss           | 0.352       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 646          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075585647 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.000922     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0453       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.266        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50           |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071426425 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.00122      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0342       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 0.205        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010538045 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.000434    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 737         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009751833 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.000398    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010780363 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.00103     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.0895      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppo = ppo.learn(STEP_LIMIT*1000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n",
      "Observation is: [0 0]\n",
      "Reward is: -1\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "obs, _ = env.reset()\n",
    "for _ in range(200):\n",
    "    ppo.predict(obs)\n",
    "    action, _ = ppo.predict(obs)\n",
    "    obs, reward, _, _, _ = env.step(action)\n",
    "    print(f\"Observation is: {obs}\")\n",
    "    print(f\"Reward is: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaosl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pokerl-qa45OdQw-py3.10\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.tick to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.tick` for environment variables or `env.get_wrapper_attr('tick')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: [ 6  3 38]\n",
      "position: [ 6  4 38]\n",
      "position: [ 6  5 38]\n",
      "position: [ 5  5 38]\n",
      "position: [ 3  5 38]\n",
      "position: [ 2  5 38]\n",
      "position: [ 1  5 38]\n",
      "position: [ 1  6 38]\n",
      "position: [ 1  7 37]\n",
      "position: [ 2  7 37]\n",
      "position: [ 3  7 37]\n",
      "position: [ 4  7 37]\n",
      "position: [ 5  7 37]\n",
      "position: [ 6  6 37]\n",
      "position: [ 6  5 37]\n",
      "position: [ 6  4 37]\n",
      "position: [ 7  3 37]\n",
      "position: [7 3 0]\n",
      "position: [5 5 0]\n",
      "position: [6 5 0]\n",
      "position: [7 5 0]\n",
      "position: [7 6 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m last_info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mtick()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtick\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m k:\n",
      "File \u001b[1;32m~\\Documents\\pokeRL\\pokerl\\env\\pokemonblue.py:22\u001b[0m, in \u001b[0;36mPokemonBlueEnv.tick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Tick is 24 gameboy tick (each movement take 24 gameboy tick)\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tick \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTick: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tick)\n",
      "File \u001b[1;32m~\\Documents\\pokeRL\\pokerl\\env\\pyboygym.py:92\u001b[0m, in \u001b[0;36mPyBoyGym.tick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tick \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTick: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tick)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyboy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_info()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_info = env.tick()\n",
    "while True:\n",
    "    info = env.tick()\n",
    "    for k, v in info.items():\n",
    "        if \"tick\" in k:\n",
    "            continue\n",
    "        if (last_info[k] != v).any():\n",
    "            print(f\"{k}: {v}\")\n",
    "            last_info = info\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tick': 0,\n",
       " 'pokemon_level': array([0, 0, 0, 0, 0, 0]),\n",
       " 'badges': array(0),\n",
       " 'position': array([0, 0, 0]),\n",
       " 'absolute_position': array([0, 0]),\n",
       " 'owned_pokemon': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rewardHistory': deque([], maxlen=10000)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PokemonBlueEnv(interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [00:11<00:00, 88.53it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m ppo\u001b[38;5;241m.\u001b[39mpredict(observation)\n\u001b[0;32m      7\u001b[0m     observation, reward, truncated, terminated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaosl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pokerl-qa45OdQw-py3.10\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaosl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pokerl-qa45OdQw-py3.10\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:276\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    272\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m:\n\u001b[0;32m    277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_rollouts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, callback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer, n_rollout_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'dict'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "observation, info = env.reset()\n",
    "done = False\n",
    "for i in tqdm(range(1000)):\n",
    "    action, _states = ppo.predict(observation)\n",
    "    observation, reward, truncated, terminated, info = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import a2c, dqn, ppo, td3\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from pokerl.agent.tools import get_device\n",
    "\n",
    "env = gym.make(\"Acrobot-v1\")\n",
    "\n",
    "agent = ppo.PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    device=\"cpu\",\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | -194     |\n",
      "| time/              |          |\n",
      "|    fps             | 1795     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 193          |\n",
      "|    ep_rew_mean          | -192         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059554596 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.972       |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    value_loss           | 76.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004588865 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | -176         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1208         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067129745 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.924       |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 176          |\n",
      "|    ep_rew_mean          | -175         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1188         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060762693 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.827       |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.64         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 40.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1171        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004266989 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 164        |\n",
      "|    ep_rew_mean          | -163       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1159       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00785982 |\n",
      "|    clip_fraction        | 0.0643     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.825     |\n",
      "|    explained_variance   | 0.813      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    value_loss           | 44.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 156         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1152        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006043353 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | -140        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1139        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189712 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | -131        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003545905 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | -119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1129        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009700642 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1125        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047224 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 106          |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1122         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047048423 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 103          |\n",
      "|    ep_rew_mean          | -102         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1118         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025806304 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -99.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1117         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051038023 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99.2         |\n",
      "|    ep_rew_mean          | -98.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1115         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025245496 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.8         |\n",
      "|    ep_rew_mean          | -94.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1112         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033820788 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.9        |\n",
      "|    ep_rew_mean          | -94.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1112        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003604845 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.6        |\n",
      "|    ep_rew_mean          | -91.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1110        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002740236 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92           |\n",
      "|    ep_rew_mean          | -91          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1110         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036570893 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.325       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.3         |\n",
      "|    ep_rew_mean          | -91.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1109         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036707895 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.01         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.9         |\n",
      "|    ep_rew_mean          | -92.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1108         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010401867 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.289       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.3         |\n",
      "|    ep_rew_mean          | -91.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1106         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021081902 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.274       |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.28         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94           |\n",
      "|    ep_rew_mean          | -93          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1106         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017146482 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.282       |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.68         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | -94.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1106        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002281781 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92           |\n",
      "|    ep_rew_mean          | -91          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1105         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028694936 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91          |\n",
      "|    ep_rew_mean          | -90         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1106        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002264285 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.2        |\n",
      "|    ep_rew_mean          | -85.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1106        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002409497 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.5         |\n",
      "|    ep_rew_mean          | -82.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1105         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024238508 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.55         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.9         |\n",
      "|    ep_rew_mean          | -81.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1103         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012495749 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.88         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.5         |\n",
      "|    ep_rew_mean          | -81.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1103         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026980005 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.88         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.7         |\n",
      "|    ep_rew_mean          | -83.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1101         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012598899 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.7         |\n",
      "|    ep_rew_mean          | -83.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1100         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012447014 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.179       |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.78         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 89.5         |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1100         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015615122 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.192       |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 90.7         |\n",
      "|    ep_rew_mean          | -89.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1100         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012028543 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.8        |\n",
      "|    ep_rew_mean          | -88.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1099        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001526643 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.169      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.82        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.6         |\n",
      "|    ep_rew_mean          | -86.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1097         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015749822 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.31         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.6         |\n",
      "|    ep_rew_mean          | -81.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1096         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017230175 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.57         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.4         |\n",
      "|    ep_rew_mean          | -82.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1096         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020836093 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.63         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 83.2         |\n",
      "|    ep_rew_mean          | -82.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011080257 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.36         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00073     |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.1         |\n",
      "|    ep_rew_mean          | -86.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011350657 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.146       |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 17.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 89.5         |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1094         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015040324 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.9         |\n",
      "|    ep_rew_mean          | -85.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011214016 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.5         |\n",
      "|    ep_rew_mean          | -85.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018302001 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.134       |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.27         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.2         |\n",
      "|    ep_rew_mean          | -83.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016196267 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 7.88         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.7         |\n",
      "|    ep_rew_mean          | -81.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006277123 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | 6.64e-05     |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.3         |\n",
      "|    ep_rew_mean          | -84.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011871399 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.134       |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.51         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 9.34         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.9        |\n",
      "|    ep_rew_mean          | -84.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002461554 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.27        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.4         |\n",
      "|    ep_rew_mean          | -85.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017202343 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.91         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = agent.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.9915062e-06 9.9776387e-01 6.6837676e-02 3.5921879e-02\n",
      " 9.4700865e-02] {}\n",
      "2 None\n",
      "Observation is: [ 0.99998754 -0.0049965   0.993651    0.11250681 -0.08324838  0.35477015]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9995197  -0.03099017  0.9795182   0.20135584 -0.16842666  0.5252706 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9976735  -0.06817307  0.9513012   0.30826288 -0.1929538   0.55648196]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9946283  -0.10351071  0.9149288   0.40361533 -0.15201782  0.44306067]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9921127  -0.12534912  0.88551056  0.46461922 -0.06212005  0.2213518 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.99192476 -0.1268278   0.87726724  0.4800023   0.0476535  -0.04920846]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99662924 -0.08203755  0.92156583  0.38822216  0.39282143 -0.95148295]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99974364  0.02264208  0.99093354  0.1343528   0.62721616 -1.6304858 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9881924   0.15321806  0.9754527  -0.22020897  0.64323145 -1.8489991 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.96556693  0.26015475  0.84254164 -0.5386312   0.4176336  -1.5461646 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9518574   0.3065413   0.68328166 -0.7301549   0.05537522 -0.9182472 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9597064   0.2810046   0.5986344  -0.80102235 -0.3148384  -0.18216491]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.98572314  0.16837426  0.6719367  -0.7406086  -0.81906503  1.1137187 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9995122  -0.03123026  0.8791045  -0.47662905 -1.1475008   2.1997733 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9640391  -0.26576042  0.9999696   0.00779723 -1.1647815   2.7165775 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8926798  -0.45069137  0.86293405  0.5053165  -0.7589663   2.3769407 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.84999585 -0.52678937  0.60409933  0.79690903 -0.09348935  1.4970796 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8756764  -0.48289838  0.43717304  0.8993774   0.5882722   0.45669386]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9523386  -0.30504304  0.4976296   0.8673896   1.3104491  -1.1226231 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 9.9999958e-01  8.8844931e-04  7.7599210e-01  6.3074267e-01\n",
      "  1.7431130e+00 -2.4897165e+00]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9361035   0.35172462  0.9951997   0.09786496  1.7563567  -3.1933193 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.78752977  0.6162766   0.8694083  -0.49409428  1.2067097  -2.7944362 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.6833409   0.73009944  0.55910593 -0.8290962   0.30832773 -1.7610706 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.7084505   0.7057605   0.3522388  -0.93591017 -0.6499816  -0.55740845]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.85324323  0.5215132   0.416214   -0.9092667  -1.6556063   1.250739  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9897515  0.1428005  0.7541052 -0.6567536 -2.330277   2.9418795]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.94046307 -0.33989587  0.9998068  -0.01965627 -2.4506488   3.7971609 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7090928  -0.70511514  0.76940536  0.6387608  -1.8035275   3.134843  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5038352  -0.8637998   0.36464527  0.9311465  -0.7680392   1.89      ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.46732017 -0.88408816  0.12186459  0.99254674  0.3513012   0.6168084 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.6304845  -0.7762018   0.1824649   0.98321235  1.5815947  -1.2535244 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.89302564 -0.45000583  0.5932393   0.8050262   2.5879495  -3.2669916 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9932773   0.11575909  0.9937265   0.11183782  3.1086988  -4.721653  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.7631817   0.64618397  0.70065457 -0.7135007   2.603212   -4.031895  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.43391615  0.90095323  0.12310036 -0.9923942   1.552847   -2.4946303 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.25180623  0.96777767 -0.23334396 -0.9723943   0.3806454  -1.1230279 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.30777994  0.95145756 -0.28015485 -0.9599548  -0.95501494  0.64828134]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5892539   0.80794793  0.03785836 -0.99928313 -2.1943305   2.6250625 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9240311   0.3823174   0.71048814 -0.7037092  -3.2430522   4.9003024 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9527106  -0.30387902  0.94248563  0.33424672 -3.5485156   5.822109  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.59061176 -0.8069559   0.21649598  0.9762835  -2.6503468   4.124325  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.21390219 -0.9768551  -0.41826096  0.9083269  -1.4956851   2.4437943 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.03773512 -0.9992878  -0.7043049   0.70989764 -0.2779448   1.0843272 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.11671944 -0.99316496 -0.73563796  0.67737496  1.0629555  -0.6444021 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.4414966  -0.89726293 -0.4889163   0.87233067  2.314237   -2.568054  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8564521  -0.5162264   0.23018189  0.97314763  3.3645077  -4.9521646 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.97728217  0.2119423   0.9949946   0.09992878  4.0305285  -7.0707355 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.5823914   0.81290853  0.35754678 -0.93389523  3.1237583  -5.545899  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.12673771  0.99193627 -0.5146871  -0.85737807  1.8215932  -3.6279871 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.10815864  0.99413365 -0.90042627 -0.43500867  0.54088664 -2.217818  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.09360456  0.99560946 -0.9905269  -0.13731894 -0.67816556 -0.90260136]\n",
      "Reward is: -1.0\n",
      "1 None\n",
      "Observation is: [ 0.16623265  0.98608655 -0.9938364  -0.1108568  -1.9238734   0.64027447]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6234807   0.7818388  -0.91511583 -0.403191   -3.0809016   2.4108686 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9774595   0.211123   -0.46652153 -0.88450986 -3.646597    4.326786  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.86615264 -0.49977952  0.549867   -0.8352522  -3.6709442   6.3074265 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.34598657 -0.93823946  0.93606067  0.35183865 -3.066757    6.6699557 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.101519   -0.9948336   0.04891855  0.9988028  -1.4177822   4.9036384 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.2096475 -0.977777  -0.7013251  0.7128415  0.3060257  3.3936634]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.00513038 -0.9999868  -0.9657111   0.25961903  1.8058723   1.9095988 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.4720834  -0.8815539  -0.99972045  0.02364266  3.009473    0.5320407 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.92939043 -0.36909816 -0.9985846   0.05318588  3.8953843  -0.7061737 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.91324157  0.40741846 -0.968049    0.25076115  3.9191375  -1.1590993 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.42608073  0.90468514 -0.8938778   0.4483107   3.091949   -0.8342797 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.06635965  0.99779576 -0.85394734  0.52035946  1.9656104   0.08457209]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.33354834  0.942733   -0.9312469   0.36438885  0.79255     1.6769638 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.37597865  0.92662835 -0.99230605 -0.12380918 -0.36419654  3.2916248 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.1704332   0.9853692  -0.5818378  -0.81330484 -1.8478566   5.034954  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.37315556  0.92776877  0.59292144 -0.8052603  -3.7492766   7.756686  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.956643    0.29126316  0.68239766  0.7309811  -4.7839394   8.867371  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.81656253 -0.577257   -0.6885681   0.7251716  -4.2979674   6.283366  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.17680448 -0.984246   -0.96135163 -0.2753235  -3.3702157   4.7996645 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.3683531  -0.92968595 -0.4139479  -0.91030055 -2.2115426   3.8731723 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.6642221  -0.7475352   0.25328892 -0.96739066 -1.3225327   2.9525723 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.7941688  -0.60769725  0.6874652  -0.7262173  -0.6112401   2.090981  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.82898194 -0.5592754   0.8941023  -0.4478628   0.00393217  1.4333051 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.7938906  -0.60806066  0.97471064 -0.22347075  0.6028819   0.9844118 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.6666383  -0.74538136  0.99789625 -0.06483141  1.2984354   0.62053233]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.3488611  -0.93717444  0.9985629  -0.05359308  2.4735622  -0.5306603 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.26640627 -0.9638608   0.9621147  -0.272645    3.7697732  -1.6091853 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8983578  -0.43926448  0.81943846 -0.57316715  4.5253487  -1.4166019 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9153741   0.40260437  0.7610636  -0.6486773   3.9444983   0.6432009 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5152412   0.85704523  0.9610271  -0.27645418  2.1894517   3.4159348 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.23126324 0.9728912  0.860937   0.50871164 1.0598778  4.4194875 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.06176751 0.99809057 0.14934291 0.98878545 0.7154273  4.4587436 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.06058637  0.998163   -0.70636356  0.7078492   0.48683128  5.0171704 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.08824602  0.9960987  -0.94022787 -0.340546   -0.47654513  6.5080643 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.254624   0.9670401  0.3399568 -0.9404411 -3.1818516  9.59355  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8928056   0.45044228  0.5567567   0.83067566 -4.5600686  11.160717  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9437959  -0.33052877 -0.9768414   0.2139647  -3.5999687   8.763055  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.51432616 -0.85759467 -0.02056711 -0.99978846 -3.5112023   9.37641   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.19071727 -0.981645    0.8920172   0.45200145 -3.3320277  10.424619  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.5358408  -0.84431905 -0.6355271   0.7720786  -0.29126003  7.5481434 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.41235635 -0.91102266 -0.8936312  -0.44880202  1.1650362   6.2177324 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.25126398 -0.9679186   0.14513563 -0.9894118   0.41662657  6.5483866 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-2.3318873e-01 -9.7243148e-01  9.9999362e-01  3.5700495e-03\n",
      "  1.1114310e-01  7.4550939e+00]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.02070954 -0.99978554  0.29770622  0.95465755  2.856555    4.5704103 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7971933  -0.6037241  -0.13958108  0.99021065  5.8940434  -0.2930357 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.7979334   0.60274565  0.4306003   0.9025427   6.671709   -5.2524557 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.346791    0.93794245  0.98779285 -0.15577333  5.9611077  -6.7631016 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9927809   0.11994174  0.22275783 -0.9748738   5.172963   -5.1205606 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.5790444 -0.815296  -0.6536674 -0.756782   5.801166  -4.4470663]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.6356195  -0.77200246 -0.99831986  0.05794385  7.2020307  -5.0293775 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8408702   0.5412368  -0.25319874  0.96741426  7.0537367  -7.898441  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ -0.35124388   0.936284     0.99535537  -0.09626895   6.470475\n",
      " -10.532075  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9988965   0.0469667  -0.38170534 -0.92428404  5.3469863  -8.078034  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.48688468 -0.87346625 -0.918498    0.39542562  5.946922   -8.44551   ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [  0.74146795  -0.6709883    0.823412     0.567444     7.7377653\n",
      " -13.471545  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.7110283  0.7031634 -0.3038237 -0.9527283  6.829872  -9.487612 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.4649798   0.88532126 -0.95407575  0.2995654   5.8497505  -6.9343553 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-9.9999958e-01  9.2072197e-04  1.5560448e-01  9.8781943e-01\n",
      "  5.2923236e+00 -7.7152696e+00]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.40473965 -0.914432    0.9335493  -0.35844904  6.3206124  -9.656926  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.8071054 -0.5904073 -0.5102245 -0.8600412  7.310136  -7.2911057]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.62573254  0.7800377  -0.97723967  0.21213835  7.5422735  -5.708174  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.6344744   0.77294385 -0.14471646  0.98947316  6.1204977  -6.666304  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.95204115 -0.3059701   0.9816309   0.19078985  6.1115613  -8.532791  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.03018501 -0.9995443   0.09672449 -0.9953112   6.8827286  -7.5127864 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99977684 -0.02112516 -0.91375715 -0.4062609   8.155181   -5.0311427 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 3.1664718e-03  9.9999499e-01 -8.8990539e-01  4.5614508e-01\n",
      "  7.4277720e+00 -4.3650866e+00]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9779025   0.20906162 -0.10504923  0.994467    6.4081473  -5.842684  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.43056485 -0.90255964  0.9809705   0.1941567   7.242436   -8.9376545 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8900691  -0.45582563  0.10061713 -0.9949252   7.9765596  -6.4614043 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.45563567  0.89016634 -0.59540313 -0.8034271   7.290119   -0.8500856 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.6479405  0.761691  -0.2889487 -0.9573446  4.201216   4.072522 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.91547734  0.40236953  0.8099753  -0.586464    0.5304879   8.017093  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.9281874  0.3721132  0.4913486  0.870963   0.5806801  8.002594 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.99992645 -0.01212798 -0.77038944  0.6375736   3.3905177   5.9745255 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.6646205  -0.74718106 -0.92509353 -0.3797394   4.342808    5.244872  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.02144335 -0.99977005  0.01380722 -0.9999047   2.3933425   7.172916  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.2197933  -0.9755465   0.973001    0.23080097  0.9384443   9.696751  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7591082  -0.65096444 -0.05157636  0.998669    5.7542562   3.2990386 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.75725925  0.65311444 -0.03288     0.9994593   7.7452335  -3.095995  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.60649467  0.7950876   0.8627928   0.5055577   7.251999   -7.020419  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.8796914  -0.4755449   0.6331293  -0.77404606  7.0342364  -6.4862556 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.4001225  -0.91646165 -0.33720437 -0.94143146  7.89281    -3.4934907 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9167945   0.39935938 -0.55222076 -0.8336979   7.1877146   1.4967897 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.1603585   0.9870588   0.38179132 -0.9242486   2.3284843   8.332906  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.05569792  0.99844766  0.6124386   0.79051816  0.19028623 10.708293  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.31428647  0.9493282  -0.91334414  0.40718848  3.181182    8.077182  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.6951145   0.718899   -0.1827658  -0.9831565   0.07934873 10.978304  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.30007207  0.95391655  0.5686012   0.82261336 -2.9491105  14.285358  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.0458983   0.99894613 -0.9241659  -0.38199136 -1.1591192  12.993701  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7385929   0.67415166  0.8179037   0.5753552  -5.873521   17.803417  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9974269  -0.07169028 -0.8690545  -0.49471638 -3.368272   14.255109  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.37153736 -0.928418    0.5986702   0.80099565 -5.555806   17.682434  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.16262966 -0.9866872  -0.7797902  -0.6260409  -1.8314202  13.471718  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.79766446 -0.6031015   0.75712496  0.65327007 -4.0805745  16.164206  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.9179002  -0.3968113  -0.95884943 -0.28391507  0.14101766 12.5813675 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.99882567  0.04844858  0.99517035  0.09816269 -4.143017   16.362022  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.89373654  0.44859225 -0.9891059   0.14720565  0.29859012 12.538845  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.65312856  0.75724703  0.93069786 -0.3657889  -4.778812   17.169199  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.04827654  0.998834   -0.9375351   0.34789062 -1.3331879  12.946894  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6481313   0.76152855  0.88766026 -0.46049896 -5.9594593  18.17944   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9941663  -0.10785769 -0.9371544   0.34891492 -2.1403878  12.210604  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7757413  -0.6310511   0.63332087 -0.7738893  -4.3990088  15.191531  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.21769926 -0.9760159  -0.33775076  0.9412356  -0.7758731  10.674763  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.3931418  -0.9194779  -0.82469815 -0.5655731   1.3872887   8.65561   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.3958231  -0.9183268   0.86195385 -0.5069867  -1.3204745  11.772407  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 3.8407737e-01 -9.2330092e-01  7.1724155e-03  9.9997425e-01\n",
      "  2.3132281e+00  7.5535316e+00]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9640385  -0.2657627  -0.82188845  0.5696485   6.156601    2.6073258 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.48673242  0.87355113 -0.94016284  0.34072554  6.7158813   0.5843336 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.68980914  0.7239913  -0.97928524  0.20248556  5.9704223   1.0030148 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.93818754 -0.34612733 -0.99938715 -0.03500413  5.818453    1.2334372 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 7.2205759e-04 -9.9999976e-01 -9.7100878e-01 -2.3904382e-01\n",
      "  6.4426360e+00  8.1809819e-01]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.97629225 -0.21645646 -0.92255336 -0.38586947  6.8490376   1.1591752 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5524421   0.8335513  -0.5736619  -0.81909215  4.535389    5.087235  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.21079443  0.9775304   0.8566326  -0.51592696 -0.7310233  11.200835  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.3568344   0.9341676  -0.07785501  0.9969647   0.29122892  9.37596   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.11944865  0.9928404  -0.96536833 -0.26089075  1.1432393   9.177566  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.35612813  0.93443716  0.8358291  -0.5489898  -3.8096204  14.341681  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8746503   0.48475447 -0.52017957  0.8540569  -2.006619   11.054485  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9894705   0.14473493 -0.39856082 -0.9171419  -2.626009   11.972854  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7554547  -0.65520084  0.5770049   0.8167407  -4.2493534  14.946893  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.47109315 -0.8820835  -0.96744174 -0.25309393 -0.5118415  10.8446455 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.15233782 -0.98832846  0.8843299  -0.46686247 -2.9947288  13.664556  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.13069876 -0.9914221  -0.3477934   0.93757117  1.4009433   8.843683  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5291384  -0.84853554 -0.9843421  -0.17626868  4.509793    5.9656477 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 9.5668763e-01 -2.9111648e-01  5.9822327e-03 -9.9998212e-01\n",
      "  1.8963733e+00  9.0401707e+00]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9598151  -0.2806333   0.72075087  0.69319415 -0.01295279 12.00009   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.96534103  0.26099163 -0.8116673   0.58412     5.028185    6.113279  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.23946683  0.9709045  -0.8533367  -0.5213602   4.325967    7.08402   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-1.1397503e-02  9.9993503e-01  8.4518814e-01 -5.3446889e-01\n",
      " -1.8163532e+00  1.3421876e+01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.28518787  0.95847166 -0.3991095   0.91690326  0.21154381 10.400338  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.15088794  0.9885509  -0.61951596 -0.78498405 -0.47238865 11.641509  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7564198   0.6540865   0.68018734  0.7330383  -4.5886655  16.238966  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.98611176  0.16608302 -0.8933332  -0.44939488 -2.2051187  13.337729  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.72199255 -0.69190085  0.7788374   0.62722594 -5.184075   17.226229  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.33427942 -0.942474   -0.94378376 -0.33056343 -0.78474754 12.37443   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.16316742 -0.9865984   0.99905807  0.04339356 -3.6955354  15.601606  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.35377797 -0.93532944 -0.87972766  0.47547793  2.466525    9.738334  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.17786391 -0.9840551  -0.17784801 -0.98405796  1.4381886  10.540979  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.11054162 -0.9938715   0.6705266   0.7418854   0.03706754 12.917428  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.76378286 -0.64547324 -0.8630678   0.50508803  6.8846607   5.425034  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.66422737  0.7475306  -0.9408989  -0.33868748  7.254985    5.2506733 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.11821367  0.99298817  0.47870758 -0.8779744   0.4951085  12.745224  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-7.4480675e-02  9.9722248e-01 -4.4506555e-03  9.9999011e-01\n",
      "  1.2108617e+00  1.1105227e+01]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.6327378   0.77436614 -0.9262363  -0.3769435   2.9750764  10.254764  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.55963266  0.8287408   0.9967639  -0.08038481 -3.368696   16.074757  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.22762196  0.9737496  -0.9447894   0.32767808  0.7329448  12.093001  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.05324553  0.99858147  0.7977051  -0.60304767 -4.527361   17.300163  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7304423   0.68297446 -0.8242364   0.5662459  -1.2198975  12.180567  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.94997275  0.31233287  0.4560165  -0.8899713  -4.3321986  15.911751  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.89178675 -0.45245594 -0.35792875  0.9337489  -1.7765725  11.95528   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.83344895 -0.5525965  -0.5819315  -0.81323785 -0.7759423  10.977413  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.4590107  -0.8884308   0.88273054  0.4698795  -2.9362879  14.1543255 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.4367418  -0.8995869  -0.91987866  0.39220312  2.557405    8.666499  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.83203405 -0.5547246  -0.2624101  -0.96495646  1.4751917   9.741762  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7607408  -0.6490558   0.7810927   0.62441504 -0.807277   13.131047  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9721424  -0.23439108 -0.85797536  0.5136908   5.071504    6.67597   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6648638   0.7469646  -0.73508155 -0.6779787   4.1783257   7.951262  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5661716   0.8242874   0.99955356 -0.02987791 -2.1292286  14.833311  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6317322   0.7751867  -0.81776464  0.57555276  2.2273307   9.898358  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.37177545  0.9283227  -0.03958675 -0.99921614 -0.8939117  13.243846  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.80670846  0.59094965  0.10949878  0.9939869  -2.4623096  15.087395  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.89034003  0.45529616 -0.5239564  -0.85174507 -1.5927768  14.610464  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9247826  -0.38049597  0.0459512   0.9989437  -4.066905   18.597778  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6935864  -0.72037345  0.05217569 -0.9986379  -2.9299505  17.396025  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.25076473 -0.96804804 -0.26661596  0.9638029   0.63712066 12.776157  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7635724 -0.6457222 -0.6840679 -0.7294183  2.8463824 11.088673 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.678821   -0.7343038   0.7554512   0.65520495 -1.3661889  16.044428  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9669806  -0.2548501  -0.9959184   0.09025795  5.6085486   9.216344  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9292611   0.3694237   0.61801285 -0.786168   -0.23282336 15.418537  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8628782   0.505412   -0.2847496   0.95860195  4.1744957   8.448277  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.15662336  0.9876584  -0.99996537  0.00832533  6.377511    6.026059  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.8642518   0.5030595   0.01197407 -0.9999283   1.5374086  10.748294  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.78907526  0.61429656  0.47930223  0.8776499  -0.7238204  13.35534   ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.96198636  0.27309754 -0.9826479  -0.18548077  2.9214275  10.900392  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.958088    0.28647405  0.9629425  -0.26970682 -2.9635282  15.989695  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.85578865  0.51732564 -0.8504335   0.5260826   2.0615833  11.108583  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9505241   0.31065091  0.25520548 -0.9668868  -1.449077   14.205692  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.7209828   0.692953   -0.07846811  0.99691665 -0.9229392  13.314584  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.787335    0.6165255  -0.5400168  -0.84165424 -0.6233428  13.82803   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.1384669   0.99036705  0.2231751   0.97477835 -4.3231463  18.02973   ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.44432914  0.8958636  -0.0479508  -0.9988497  -4.460146   18.666574  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9907395  0.1357764 -0.4786848  0.8779868 -2.692194  15.204698 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.937544   -0.34786668  0.329944   -0.9440005  -4.0920715  16.97148   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.52082694 -0.8536623  -0.37328556  0.9277165  -0.35873264 11.936106  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.72863156 -0.6849059  -0.63103956 -0.77575064  1.1521618  10.584573  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5415726  -0.840654    0.9037806   0.42799607 -1.9821194  14.522049  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7407347  -0.6717977  -0.88643986  0.46284375  4.485845    7.837729  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.97750545  0.21091005 -0.493446   -0.8697764   3.2650204   9.468253  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9859181   0.167229    0.789116    0.61424416 -1.3779495  15.088473  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.86259514  0.5058949  -0.98934644  0.14558043  3.9903347   9.672551  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6568522   0.7540193   0.6221076  -0.78293175 -1.730161   15.512229  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8173698   0.57611334 -0.40646446  0.9136666   1.5201167  10.4340515 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.43702057  0.8994515  -0.69909275 -0.715031    1.4511657  11.025693  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.77356255  0.63372     0.77808565  0.6281582  -3.630416   16.416498  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.90588146  0.42353135 -0.95531887 -0.29557723 -0.27678385 12.961451  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.97141135 -0.23740254  0.8836621   0.46812534 -4.7608576  17.67633   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 8.1859386e-01 -5.7437277e-01 -9.7147536e-01 -2.3714058e-01\n",
      " -3.8459897e-03  1.2596115e+01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.47683442 -0.87899315  0.99211097  0.125363   -3.7722557  16.648558  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.3630227  -0.9317803  -0.95234984  0.3050079   2.9854903   9.993997  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.74712485 -0.66468376  0.21915504 -0.97569007  0.36877993 12.602675  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.7258091  -0.6878962   0.24006332  0.97075725  1.62523    11.23979   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9786792   0.2053949  -0.95655555  0.29155013  6.784001    5.339585  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.10696223  0.9942631  -0.61792517 -0.78623694  4.29032     8.3823185 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.02758782  0.99961936  0.96031797  0.27890748 -2.0366633  15.063577  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 9.9863941e-03  9.9995011e-01 -9.6122795e-01  2.7575496e-01\n",
      "  2.3135409e+00  1.0970685e+01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-1.11228546e-04  1.00000000e+00  6.88710749e-01 -7.25036204e-01\n",
      " -3.25132537e+00  1.63515434e+01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5359305   0.8442621  -0.63170743  0.7752069  -0.34319055 11.789194  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 6.4055246e-01  7.6791441e-01 -6.1615468e-03 -9.9998105e-01\n",
      " -2.6554015e+00  1.4529307e+01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.99508154  0.09905925 -0.03247781  0.99947244 -3.101411   14.968691  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9748872  -0.22269924 -0.41930297 -0.9078464  -2.1819305  14.137442  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.5074087  -0.86170554  0.18918656  0.98194116 -3.4154568  16.811682  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.38719943 -0.921996   -0.51401705 -0.85778    -0.72985893 14.202275  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.19845752 -0.9801095   0.24947679  0.96838075 -2.1950278  16.92983   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.05648007 -0.9984037  -0.6138272  -0.7894404   1.1922761  14.347475  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.33874536 -0.9408781   0.16978215  0.9854816  -1.2558687  18.092518  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.15859798 -0.98734325 -0.39127427 -0.92027414  1.5409766  16.854631  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.12788646 -0.9917888  -0.15063468  0.9885895   2.4108977  15.779616  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9873836  -0.15834649 -0.5038749  -0.8637766   4.821905   16.648388  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9667334   0.25578603 -0.18368576  0.982985    3.251676   16.801876  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.05529494  0.99847007 -0.11820356 -0.99298936  5.334763   18.492441  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.88130337  0.47255093 -0.274047    0.9617163  12.31993    -0.22951649]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [  0.67607766  -0.73683035   0.98981553   0.14235613  12.566371\n",
      " -14.13618   ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.03571872  0.9993619  -0.24467841 -0.9696043  10.535701   -2.5045574 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9962236  -0.08682466  0.26346898 -0.96466786  5.2319913   7.034142  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.7395024  -0.673154    0.7921311   0.61035097  3.3622055   9.831495  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.52212495 -0.85286903 -0.06595482  0.9978226  10.214039   -1.1932446 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [  0.3098526    0.9507846    0.98927355   0.1460747   11.578108\n",
      " -11.187325  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9637598  -0.26677164  0.07509154 -0.99717665  9.652646   -3.5598857 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.42653266 -0.9044722   0.13672483 -0.99060905  7.168625    4.477885  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.972574   -0.23259377  0.92633194  0.37670824  3.6398723  10.622336  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.45812863 0.8888859  0.03218421 0.999482   9.35094    0.14138965]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.999145    0.04134334  0.7928362   0.6094348  10.371282   -8.1631975 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.50660694 -0.86217713  0.524692   -0.85129213 10.636836   -5.9558325 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.6800086   0.7332042   0.430846   -0.90242547  7.0154686   5.1919837 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.12455599  0.9922126   0.769119    0.63910556  3.6545727   9.562301  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9753902   0.22048587 -0.30016312  0.9538879   8.522686    1.8517979 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.23517781 -0.9719524   0.28013378  0.959961   11.515676   -8.476352  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [  0.45969298   0.8880779    0.53345877  -0.8458261   11.809407\n",
      " -10.170515  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.99606687 -0.08860452 -0.37079716 -0.92871386  9.376516    0.02939858]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 1.3035366e-04 -1.0000000e+00  4.0143102e-01 -9.1588926e-01\n",
      "  5.0018435e+00  7.9604454e+00]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.70362186 -0.7105746   0.67343074  0.7392503   5.029523    8.356876  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.6837843   0.7296842   0.19504908  0.9807935  10.128964   -2.7544372 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9730795   0.23046973  0.99994254 -0.01071813 10.398266   -9.137032  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.25101137 -0.96798414  0.19399033 -0.98100346  9.863734   -2.8810804 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9514944  0.307666   0.6072143 -0.7945381  5.7012963  7.439794 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.35551018 0.9346724  0.6023497  0.7982323  5.110598   7.325602  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.87053466  0.49210715 -0.05035338  0.99873143  8.716097   -0.30032468]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.12044237 -0.9927203   0.7721498   0.6354406  10.926863   -9.08473   ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8481844   0.5297011   0.47155344 -0.8818375  10.454785   -5.1980815 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.620973    0.78383195  0.492363   -0.87038994  5.973381    4.85443   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9943025   0.1065949   0.8868473   0.46206266  3.4068418   8.347031  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.50212055 -0.8647976   0.06678561  0.9977673   8.436436    0.716416  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99886125 -0.0477096   0.8716022   0.49021384 11.400848   -9.727785  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.5182573   0.8552247   0.43562874 -0.90012646  9.382081   -4.0600863 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.8465467  -0.5323144   0.38937977 -0.9210773   6.4440346   3.1062794 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.00810568 -0.99996716  0.9991584  -0.04101866  4.4924088   6.9534283 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.95176697 -0.30682176  0.6755322   0.73733044  8.30346     0.5757483 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.03520471  0.9993801   0.97628236  0.21650109  9.344748   -5.0337963 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.98829293 -0.15256809  0.8032793  -0.5956026   8.166734   -2.6901305 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.11174271 -0.99373716  0.74279284 -0.6695213   7.0676675   1.8864743 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.98100597 -0.19397768  0.99774605  0.06710277  6.0917745   4.78512   ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.368927   0.9294584  0.8038822  0.59478855 7.758299   0.47807258]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9421112   0.33530068  0.943664    0.33090514  8.142632   -2.8922498 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.22157675 -0.97514296  0.9323349  -0.36159593  8.726005   -3.3925288 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9940714  -0.10872912  0.82598984 -0.56368494  7.7307878   1.5663105 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [0.39330447 0.91940826 0.97144747 0.23725466 5.650808   5.1053834 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.75695133  0.65347123  0.6307325   0.7760004   7.1811886   0.88409567]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.61963713 -0.7848884   0.86020696  0.50994503  8.994541   -4.3294435 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9597788  -0.2807574   0.83937526 -0.54355234  9.923208   -4.707459  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.15917172  0.9872509   0.77815765 -0.62806904  6.6772237   3.4605722 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.7633478   0.6459877   0.896144    0.44376338  4.63462     6.040608  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.87117964 -0.4909644   0.38756052  0.92184424  7.844827    0.28171843]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.7494054  -0.66211146  0.95021653  0.31159028 10.799073   -7.988125  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.20406727  0.9789569   0.59689575 -0.8023188   9.149469   -2.364829  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.93726724  0.34861165  0.8301905  -0.55747986  5.223248    4.8482866 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.8363179 -0.5482448  0.8491027  0.5282278  5.201723   5.0061064]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.4452044  -0.89542896  0.6520339   0.7581898   9.279023   -2.5348063 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.58371836  0.81195617  0.94795203 -0.3184131  10.281      -6.6021657 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.92362577  0.38329557  0.57298774 -0.8195639   7.5219793   0.4571521 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.67260313 -0.7400034   0.9447916  -0.32767186  5.182952    4.977232  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.4131673  -0.91065514  0.8526959   0.52240765  7.1399927   2.4697413 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8330177  0.5532463  0.9435632  0.3311925  9.4657345 -3.5747535]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.738014    0.67478544  0.92697495 -0.3751233   8.297338   -2.5028892 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.7173947  -0.6966669   0.86488736 -0.50196606  6.9913354   0.96800816]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.52552533 -0.850778    0.9960027  -0.08932316  6.832807    2.7934368 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [0.888726   0.45843872 0.9657434  0.25949883 8.028061   0.43843868]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.5015837   0.86510915  0.993154    0.11681259  7.91596    -1.3842922 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.8780089  -0.47864434  0.98621786 -0.16545197  7.6711845  -1.2821406 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.47505072 -0.8799584   0.95081836 -0.30974904  7.953383    0.05043813]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8980776   0.43983704  0.99846864 -0.05532123  7.3496914   2.0887194 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.29685077  0.95492387  0.9394789   0.34260684  6.962581    1.4554143 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.98537546 -0.17039715  0.92050976  0.39071956  7.612398   -1.0358796 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.28359377 -0.9589445   0.9921717  -0.12488101  9.132956   -3.5047855 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.880857    0.47338244  0.88615495 -0.463389    8.140909    0.57262605]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.25886008  0.96591485  0.99021536  0.13954772  5.733799    4.3298373 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.99694496  0.07810758  0.7243405   0.68944246  6.999932    1.1494005 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.01691341 -0.99985695  0.93507856  0.35444057  9.589002   -4.8971405 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9047849   0.42586887  0.81027436 -0.58605075  9.496214   -2.949297  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.39719567  0.91773397  0.90684277 -0.42146912  5.947713    4.0705156 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9936082   0.11288394  0.84944797  0.52767235  5.4488454   4.3486805 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.275591   -0.961275    0.6511723   0.75892997  8.757342   -1.9174875 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9853711   0.17042226  0.96888614 -0.24750686 10.61393    -6.8052726 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.45882282  0.8885278   0.63942397 -0.7688543   7.680516    1.0154538 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9963181  -0.08573333  0.9961418  -0.08775804  4.80519     5.5485425 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.3300028  -0.9439799   0.7265281   0.68713677  7.3712897   1.6007633 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9978567  -0.06543766  0.97542304  0.22034034 10.347199   -5.680986  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.30949545  0.9509009   0.80136675 -0.5981733   8.527087   -1.5635947 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9874131  -0.15816252  0.9235317  -0.38352212  5.9508176   3.30272   ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.22468959 -0.9744304   0.940413    0.34003437  6.606473    2.9171357 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.986474   -0.16391787  0.93754596  0.34786144  9.3577585  -2.4691474 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.13748083  0.99050444  0.96213794 -0.27256307  8.727827   -2.4297676 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9936029  -0.11293091  0.9253625  -0.3790833   6.9199343   1.066081  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.10616914 -0.9943481   0.999568   -0.02939134  6.9821177   1.9391707 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9906759  -0.13623972  0.98173475  0.19025463  8.353455    0.10787199]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.02478242  0.99969286  0.996974    0.07773608  8.109733   -0.71787184]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9987059   0.05085703  0.99869597 -0.05105291  7.462972   -0.5316207 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.09287351 -0.9956779   0.9874329  -0.1580388   7.959898   -0.4890127 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.999343   -0.03624445  0.9881554  -0.15345642  8.127791    0.65490067]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [0.06740182 0.9977259  0.9955764  0.09395587 7.282359   1.4250983 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.97539794  0.22045134  0.9506285   0.31033117  7.1261473   0.46363238]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.22372675 -0.97465193  0.9949495   0.10037649  8.63643    -2.451486  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9999506   0.00994276  0.9307759  -0.36559033  8.911622   -1.249157  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.01425057  0.99989843  0.9912474  -0.13201739  6.652383    2.950689  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.94758     0.31951874  0.8870856   0.46160492  6.473531    2.2532296 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.3879154  -0.921695    0.87735504  0.47984177  8.655351   -2.2887156 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9991705  -0.04072328  0.94358766 -0.33112285  9.92435    -4.217417  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.11398116  0.9934829   0.8705186  -0.49213547  7.0920396   2.3301103 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.95981234  0.2806425   0.9496194   0.31340542  5.435284    4.538854  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.49627948 -0.8681628   0.70691085  0.7073027   8.271454   -0.65258634]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99120957 -0.13230112  0.9956788  -0.0928644  10.574165   -6.2162104 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.20735078  0.97826666  0.7458478  -0.66611636  8.013218    0.5833384 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9924344   0.12277613  0.9999562   0.00936295  5.083236    5.3750086 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.45750046 -0.8892094   0.7176472   0.69640684  7.732734    1.0210638 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.98988694 -0.14185838  0.99207526  0.12564516 10.58819    -5.9543004 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.25421733  0.9671471   0.7875107  -0.616301    8.489382   -0.740112  ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.99912935 -0.04171909  0.98404    -0.17794713  5.575168    4.492815  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.2944445  -0.95566857  0.8424127   0.53883284  7.4227195   1.7352797 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99923265 -0.03916811  0.9870695   0.160293   10.211292   -4.56379   ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.30585158  0.9520792   0.8787327  -0.4773142   8.448736   -0.92523444]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9844024  -0.17593142  0.9755811  -0.2196395   6.336083    2.895486  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.06782332 -0.99769735  0.9471872   0.32068115  7.4760933   1.6188872 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.99374723  0.11165344  0.98727566  0.1590183   9.511726   -2.4652593 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.35452345  0.93504715  0.9670798  -0.25447318  8.288881   -0.90073097]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9589776  -0.28348187  0.9861442  -0.16589051  6.998922    1.3559285 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.18384515 -0.9829552   0.99803275  0.06269447  7.9576716   0.53992414]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.94440776  0.32877648  0.9998998  -0.0141538   8.861256   -0.79063475]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-3.9561912e-01  9.1841465e-01  9.9999970e-01 -7.5156556e-04\n",
      "  7.5025325e+00  8.6707252e-01]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9607237  -0.27750677  0.9814054   0.19194667  7.3095794   0.62492615]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.33614677 -0.9418096   0.99953085  0.03062879  8.9931     -1.9707593 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.8310799   0.556153    0.9637095  -0.26695332  8.684727   -0.2990789 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.501825    0.8649692   0.99833256  0.05772453  6.6600842   2.7556322 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.9496231  -0.31339428  0.8921318   0.4517752   7.4254394   0.6773099 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.4657363  -0.8849236   0.9961441   0.08773232  9.739223   -3.8283968 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.671703    0.7408206   0.8971402  -0.4417459   8.807947   -0.51177764]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.66552824  0.7463727   0.9990137  -0.04440225  6.241247    3.5449076 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.9024354  -0.43082517  0.8555225   0.5177656   7.2293773   1.3826861 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.5832452  -0.81229615  0.98204005  0.18867256  9.983921   -4.2823224 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.5178432   0.85547554  0.8785331  -0.47768146  8.9971695  -1.1538793 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.78982985  0.613326    0.9954128  -0.09567294  5.970948    4.056256  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.830603   -0.556865    0.8310449   0.55620533  7.210867    1.6787529 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.7142548  -0.6998858   0.9755511   0.21977267 10.187791   -4.617798  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.34149027  0.9398853   0.86632305 -0.49948406  9.001019   -1.2980655 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.90366095  0.42824864  0.98088366 -0.19459519  6.1525016   3.5727596 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.6883101  -0.7254166   0.88762647  0.46056402  7.092616    2.0141957 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.83674824 -0.54758775  0.9768759   0.21380699 10.024454   -3.9264925 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.18875611  0.982024    0.90481216 -0.42581096  8.86493    -1.2547956 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.96406806  0.26565546  0.9817003  -0.19043234  6.4178295   2.909516  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.5068417  -0.86203915  0.9321011   0.3621983   7.2829175   1.7022159 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.9340419  -0.35716343  0.982305    0.1872884   9.700146   -2.8599265 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.04030927  0.99918723  0.9504554  -0.31086087  8.66124    -1.0846192 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.99217945  0.12481943  0.9946552  -0.10325208  6.5689526   2.5051098 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.31326059 -0.9496672   0.9492239   0.31460142  7.6960897   0.934115  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.99555355 -0.0941974   0.9997582   0.02199132  9.726368   -2.878406  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.15406547  0.98806065  0.9555014  -0.29498664  8.110011    0.1661352 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-9.9999708e-01 -2.4082381e-03  9.9823242e-01  5.9431229e-02\n",
      "  6.5671139e+00  2.5632141e+00]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.11402091 -0.99347836  0.93979627  0.34173518  8.316457   -0.2381628 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9812518   0.19273019  0.9930807  -0.11743413  9.783849   -2.984889  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.37347004  0.9276422   0.9527937  -0.3036185   7.639338    1.1348034 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.98509043 -0.17203721  0.9847038   0.17423674  6.5694027   2.694758  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.11992738 -0.99278265  0.93206453  0.36229232  8.818868   -1.1253303 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.88245994  0.47038752  0.97771996 -0.20991339  9.772302   -2.978628  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.5900047   0.8073998   0.94928753 -0.31440935  7.312901    1.6849186 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9255925  -0.37852153  0.9737751   0.2275127   6.6274085   2.7269647 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.39444798 -0.91891825  0.95419276  0.29919252  9.284689   -2.0569139 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.70308024  0.71111053  0.9584719  -0.28518692  9.466195   -2.2354348 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.75253755  0.65854937  0.9696874  -0.24434888  6.9844666   2.158426  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.82005286 -0.5722878   0.9579577   0.2869096   6.941782    2.196191  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.64916754 -0.76064545  0.9763548   0.21617445  9.584944   -2.6315935 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.47589174  0.87950385  0.94929355 -0.31439108  9.082389   -1.3983395 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.8752722   0.48363063  0.9874041  -0.15821871  6.808407    2.3360803 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.65816593 -0.7528729   0.9506284   0.31033143  7.3428125   1.5028298 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.85440654 -0.51960516  0.9942269   0.10729831  9.751229   -2.894668  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.22177641  0.97509754  0.9498327  -0.31275845  8.627402   -0.4594585 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-9.4971317e-01  3.1312120e-01  9.9998808e-01  4.8844721e-03\n",
      "  6.5643759e+00  2.8062062e+00]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.46300966 -0.88635325  0.9218468   0.38755444  7.9836564   0.37065881]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9813837  -0.1920576   0.9990508  -0.04356095 10.023244   -3.4830754 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.08214542  0.99662036  0.93587863 -0.35232255  8.085773    0.70720935]\n",
      "Reward is: -1.0\n",
      "1 None\n",
      "Observation is: [-0.9964928   0.08367838  0.99429095  0.10670307  6.538504    2.9010665 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.18270008 -0.9831687   0.9182999   0.39588538  8.516511   -0.49436992]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9844259   0.17580007  0.9883644  -0.15210448 10.038642   -3.423885  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.3825894  0.9239185  0.9382239 -0.3460288  7.657517   1.4208905]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.984829   -0.17352745  0.97809076  0.20817904  6.5473976   3.039778  ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.16293913 -0.9866361   0.9360802   0.35178667  9.193373   -1.8038727 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.83753484  0.546384    0.96053535 -0.27815792  9.798499   -2.7720177 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.6416553   0.76699317  0.9569687  -0.29019102  7.154785    2.205528  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.8988368  -0.43828347  0.9548996   0.29692876  6.8293114   2.5962262 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.49730676 -0.86757475  0.9438324   0.33042464  9.514099   -2.2473645 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.5866649  0.8098298  0.953929  -0.3000324  9.555546  -2.3782904]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.8489475   0.5284772   0.96334624 -0.2682612   7.022119    2.1845164 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.7054173  -0.70879227  0.96212375  0.272613    7.0885143   2.225132  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.78652924 -0.61755306  0.9693567   0.24565749  9.603864   -2.2295954 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.28816766  0.95758     0.9640272  -0.26580343  9.113999   -1.5714034 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.9633136   0.26837832  0.9823937  -0.18682267  7.0625587   1.847139  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.41936913 -0.9078158   0.97558844  0.21960694  7.567188    1.4159685 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9706426  -0.24052632  0.99767524  0.06814793  9.645265   -2.2245736 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.03384281  0.99942714  0.974054   -0.2263158   8.416448   -0.13197255]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9989602   0.04559113  0.9990616   0.04331282  6.9307837   2.102346  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.11093807 -0.99382734  0.96189505  0.27341893  8.448788   -0.25984368]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.97970724  0.20043376  0.99230677 -0.12380353  9.735081   -2.430078  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.37623495  0.9265243   0.9729804  -0.2308877   7.699508    1.2712948 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.97526497 -0.22103892  0.9785605   0.20595945  6.9579554   2.1878872 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.26666796 -0.96378845  0.97316533  0.23010696  9.281495   -1.9568326 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.79801035  0.6026438   0.9612334  -0.27573618  9.449707   -1.7180418 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.65427846  0.7562537   0.9870593  -0.16035558  7.090516    2.2895145 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.8687121  -0.49531728  0.94486374  0.32746372  7.275905    1.6943507 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.6253508  -0.7803438   0.98811203  0.15373552  9.804514   -2.9926696 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.4923073   0.87042147  0.9404274  -0.3399945   9.028875   -0.8330554 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.8579509   0.51373166  0.9971521  -0.07541724  6.7925906   2.6754227 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.65471244 -0.75587803  0.9297318   0.3682374   7.726395    0.9759699 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [ 0.8863519  -0.46301228  0.995948    0.08993081  9.908527   -2.9961684 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.1449106   0.98944473  0.94972426 -0.31308758  8.629881   -0.25621474]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9728049   0.23162605  0.9994836   0.03213317  6.6732483   2.8165123 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.3437287  -0.939069    0.9253723   0.37905955  8.295837    0.04348406]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.9999026  -0.01395475  0.9955372  -0.09436993 10.105578   -3.3748374 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.24261837  0.9701218   0.94366986 -0.33088842  7.943359    1.1116978 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.997546   -0.07001367  0.98304915  0.18334234  6.6647577   2.9530895 ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.04601863 -0.9989406   0.9206469   0.39039633  9.033914   -1.219017  ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.89131284  0.4533888   0.9732106  -0.2299157  10.040779   -3.1887684 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.6033036   0.7975116   0.9461821  -0.32363477  7.420456    1.9265825 ]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.9090014  -0.4167931   0.96565515  0.25982717  6.835309    2.787727  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [ 0.47517556 -0.87989104  0.9401987   0.3406265   9.531806   -2.0248384 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.59364325  0.8047283   0.95941216 -0.2820077   9.678644   -2.4601705 ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [-0.858372    0.51302785  0.9633942  -0.26808867  7.161731    2.1006517 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [-0.6555699  -0.75513446  0.979115    0.20330702  7.395783    1.7078779 ]\n",
      "Reward is: 0.0\n",
      "0 None\n",
      "Observation is: [ 0.8495647  -0.5274845   0.9939279   0.11003319  9.650818   -2.15366   ]\n",
      "Reward is: -1.0\n",
      "0 None\n",
      "Observation is: [ 0.22936696  0.97334003  0.97210306 -0.23455423  8.763354   -0.47175276]\n",
      "Reward is: -1.0\n",
      "2 None\n",
      "Observation is: [-0.964052    0.26571357  0.99982476  0.01872175  6.966155    2.261353  ]\n",
      "Reward is: 0.0\n",
      "2 None\n",
      "Observation is: [-0.34646764 -0.93806195  0.9521604   0.3055986   8.301322    0.04080727]\n",
      "Reward is: -1.0\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = gym.make(\"Acrobot-v1\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "print(obs, info)\n",
    "for _ in range(500):\n",
    "    action, states = agent.predict(obs)\n",
    "    print(action, states)\n",
    "    obs, reward, _, _, _ = env.step(action)\n",
    "    print(f\"Observation is: {obs}\")\n",
    "    print(f\"Reward is: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokerl-qa45OdQw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
